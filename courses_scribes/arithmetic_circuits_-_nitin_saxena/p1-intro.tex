\chapter{Introduction}
\section{Turing Machines}
Classically, computation i modeled using Turing Machine i.e. a computer program is scene as $TM$ description\parinf
\vspace{0.5cm}

\textbf{Turing Machine ($TM$)}: {$M=(\Gamma, Q,\delta)$ where \begin{itemize}
		\item $\Gamma$ $=$ Set of alphabets, say 0,1, $\vartriangleright$ (start), $\square$ (blank)
		\item $Q$ $=$ Set of states (at least it has start state = $q_s$, final state $=$ $q_f$)
		
		[whenever we say computation, we mean $q_s$ to $q_f$ finitely many steps are taken and whatever is there in tape is considered as output.]
		\item $\delta\ =$ transition function$$\delta : Q\times \underset{\substack{  (\text{Assuming 2}\\ \text{tapes one for} \\ \text{input bit and}\\ \text{other for work}\\ \text{tape for reading}\\ \text{bit at current}\\ \text{work tape head)} }}{\Gamma^2}\longrightarrow Q\times \Gamma^2\times \{\underbrace{\overset{\text{Stay}}{S},\overset{\text{Left}}{L},\overset{\text{Right}}{R}  }_{\text{head movement}} \}$$
		
		[you can think $\delta$ as your $C$ program or computer program]
\end{itemize}
\parinn

Since work tape is infinite you don't know how many steps will be taken. $TM$ abstracts every possible device
\dfn{Time and Space of $TM$}{\begin{itemize}
		\item \textbf{Time} is the number of steps for a given input $x$.
		\item \textbf{Space} is the number of worktape-cells used by $TM$ on $x$
\end{itemize}}

\section{Complexity Classes}
\dfn{$Dtime(f(n))$ and $Space(f(n))$}{For a function $f:\bbN\to\bbR_{>0}$ we can define complexity classes\begin{itemize}
		\item \textbf{$Dtime(\bmf(\bmn))$}: $\{$ Set of all those problems that can be solved on a $TM$ in time $O(f(n))$ $\}$
		\item \textbf{$Space(\bmf(\bmn))$}: $\{$ Set of all those problems that can be solved on a $TM$ in work space $O(f(n))$ $\}$
\end{itemize} }

This leads to a zoo of complexity classes
\dfn{$P,\ PSpace,\ NP,\ \bbL,\ EXP$}{
\begin{itemize}
	\item $P\coloneqq \bigcup\limits_{c>0} Dtime(n^c)$
	\item $PSpace\coloneqq \bigcup\limits_{c>0} Space(n^c)$
	\item $NP\coloneqq \bigcup\limits_{c>0} \underset{  \substack{ \downarrow \\ \text{on a non} \\ \text{-deterministic }TM}  }{Ntime(n^c)}$
	\item $\bbL\coloneqq Space(\log n)$
	\item $EXP\coloneqq $ $\{$ Problems that can be solved in time $2^{n^c}$ $\}$ 
\end{itemize}
}

\nt{
$$ \bbL\subseteq P\subseteq NP\subseteq PSpace\subseteq EXP\subseteq EXPSpace\subseteq EEXP\subseteq \cdots$$
}
There are \textbf{randomized versions} (using probabilistic $TM$)
$$\underset{ \substack{ \\ \text{zero error}\\ \text{probabilistic}\\ \text{poly-time}\\ \text{(Las-Vegas}\\ \text{Algorithms)}  } }{ZPP}\subseteq \underset{\substack{ \text{one-sided}\\\text{error} }}{RP} \subseteq \underset{ \substack{ \text{both-sided}\\\text{error}\\ \text{(Bounded error}\\ \text{Probabilistic} \\\text{poly-time)} } }{BPP} \subseteq \underset{\substack{ \text{Probabilistic}\\ \text{poly error}=\frac12\\ \text{both sided} }}{PP} \subseteq PSpace$$

\textbf{Oracle-based complexity classes}:
$$ \underset{ \substack{\ueq \\ \sum_0} }{P} \subseteq \underset{ \substack{\ueq \\ \sum_1} }{NP} \subseteq \underset{ \substack{\ueq \\ \sum_2} }{NP^{NP}} \subseteq \underset{ \substack{\ueq \\ \sum_3} }{NP^{\sum_2}}\subseteq \underset{ \substack{\ueq \\ \sum_4} }{NP^{\sum_3}} \subseteq \cdots\subseteq PH \subseteq PSpace$$This hierarchy is called Polynomial Hierarchy. Union of all of these is called $PH$

\vspace{0.5cm}
This course will take a different route to build a zoo of complexity classes

\section{Arithmetic Circuits}
Instead of seeing computation as a sequence of very simple steps (that's what $TM$ does. At each step transition is trivial but in the end something highly non trivial happens.) We'll review it as an algebraic expression

\dfn{Arithmetic Circuits}{
An arithmetic circuit $C$, over a field $\coef$, is a rooted $DAG$ as follows\begin{itemize}
	\item The \textbf{leaves} are the variables $x_1,x_2,\dots,x_n$ or field constant
	\item The \textbf{root} outputs a polynomial $C(\overline{x})\in \bbF[\overline{x}]$ (input)
\item The \textbf{Internal vertices} are gates that compute $(\times) $ or $(+ )$ in $\bbF [\overline{x}]$
\item The \textbf{edges} are called wires and they have constant labels to do scalar multiplication.
\end{itemize}
}
\thm{}{Any polynomial has a depth-2 circuit}
\begin{proof}
	In first layer you have addition and in the bottom layer you have multiplication
\end{proof}
\dfn{Size, Depth, Degree}{\begin{itemize}
		\item \textbf{Size: } The size of the $DAG$ (\# of wires) is the size of the circuit size $(c)$. Sometimes we include the bit size of the constants on the wires
		\item \textbf{Depth: }A Max-path from a leaf to the root determines the depth of the circuit.
		\item \textbf{Degree: }Degree of $c$ is the degree of intermediate polynomials computed in $c$
\end{itemize}}
\qs{}{How many monomials are there in $n$ variable $d$ degree polynomial ?}
\solve{${{n+d}\choose{d}}\approx \lt( \frac{n}{d}\rt)^d,\lt( \frac{d}{n}\rt)^n$}

\ex{}{\circuitdraw{
		\node[state] (C)
		{$+$};
		\node[state] (A) [below left=of C] {$x_1$};
		\node[state] (B) [below right =of C] {$x_2$};
		\path (A) edge node[left] {} (C);
		\path (B) edge node[right] {} (C);
		\node[state] (D) [above right=1 cm and 1 cm of C] {$\times$};
		\node[state] (E) [above left=1 cm and 2 cm of D] {$\times$};
		\node[state] (F) [above right=1 cm and 2 cm of E] {$\times$};
		\node[state] (G) [above left=1 cm and 1 cm of F] {$+$};
		\node (H) [right=2cm of G] {\LARGE{$f$}};
		\path node[below=0.5cm] {} (C) edge [bend left=10] node[above] {} (D);
		\path (C) edge [bend right=10] node[below] {} (D);
		\path (D) edge [bend left=10] node[above] {} (E);
		\path (D) edge [bend right=10] node[below] {} (E);
		\path (E) edge [bend left=10] node[above] {}  (F);
		\path (E) edge [bend right=10] node[below] {} (F);
		\path (F) edge [bend right=10] node[above] {}  (G);
		\path (E) edge [bend left=10] node[above=2mm, left=1mm] {-1} (G);
		\node[text width=10cm, left=5cm of E] {$f(x_1,x_2)=(x_1+x_2)^8-(x_1+x_2)^4$.
			\vspace{1cm}
			
			The circuit size is small because of repeated squaring
		\vspace{3cm}
		
	Another example for repeated squaring is $(1+x)^{2^n}$};
		\draw[->] (G) to (H);}
%\path (C) edge [bend left =25] node[below =0.15 cm] {$1/2$} (A);
%\path (A) edge [bend right = -15] node[below =0.15 cm] {$1/2$} (C);
%\path (A) edge [bend left =25] node[above] {$1/4$} (B);
%\path (B) edge [bend left =15] node[below =0.15 cm] {$1/2$} (A);
%\path (C) edge [bend left =15] node[below =0.15 cm] {$1/2$} (B);
%\path (B) edge [bend right = -25] node[below =0.15 cm] {$1/2$} (C);
}
\qs{Foundational Question in this area}{When a polynomial is not possible to compress by circuit representation and only way is depth-2 (worst possible way)}
\dfn{Fanin, Fanout, Formula, Family of Circuits}{\begin{itemize}
		\item \textbf{Fanin: }Maximum in-degree
		\item \textbf{Fanout: }Maximum out-degree
		\item \textbf{Formula: }A circuit with fanout=1 is called formula
\end{itemize}}
\dfn{Family of Circuits}{Suppose $\mcF\dnt\{f_1(x_1,\dots,x_i)\mid n\geq1\}$ is a family of polynomials (call it a problem). A family of circuits $\mcC\dnt \{C_i(x_1,\dots, x_n)\mid i\geq 1\}$ solves $\mcF$ $\forall\ i$, $C_i=f_i$}

In this case, we say that $\mcF$ can be solved in size bounded by $size(C_n)$ and depth bounded by $depth(C_n)$. This two functions basically tell you the circuit complexity of the set of polynomials $\mcF$

\nt{
Depth can be thought of as time (In parallel algorithm). Size can be though of as space.

This gives us a new way to measure the complexity of polynomials (or problems)
}
\section{Arithmetic Complexity Classes}
Arithmetic Complexity Classes were first defined by Valiant (1979). In particular, the arithmetic analogues of $P$ and $NP$
\dfn{$VP$ (Valiant's $P$)}{$VP$ consists of polynomial families say $\{f_n\}_n$  [$f_n$ is a $n$ variate polynomial] that can be solved or computed by Arithmetic Circuits of size-poly($n$) and degree-poly($n$)}

\qs{}{Why degree-poly($n$) condition?}
\solve{You want it to be practically implementable i.e. every aspect of the computation you would ideal want to be efficiently implementable on a turing machine. One necessary condition is degree should not blow p. We don't want circuit at a point to become too large. 

The family $\{x^{2^n}\}_n \notin VP$. Though it is computable by $O(n)$ size arithmetic circuits, its degree is not poly($n$)}

We keep some field $\bbF$ in mind while defining $VP$. 
\nt{Constants don't contribute to size or degree}

An interesting polynomial (family) in $VP$ is the \textbf{Determinant}. $$\det_n(X_{n\times n})\dnt \sum_{\pi\in Sym(n)}sign(\pi)  \overset{\substack{n^{\frac{n}2}\approx n! \\ \text{such monomials} \\ \uparrow}}{\underset{\substack{\downarrow \\ \text{Don't have same}\\\text{row or column} }}{\boxed{\prod_{i=1}^nx_{i,\pi(i)}}}}$$
\thm{}{Given a specialized $X$ we can compute $\det_n(X)$ in $P$ (nearly quadratic time!).}
\begin{proof}
	Use Gaussian Elimination
\end{proof}
\nt{This does not give $\{\det_n\}_n\in VP$ because, the above algorithm uses division, if-then-else, permutation etc.
}
What is the analogue of $NP$ (non-determinism)? Do a large sum
\dfn{$VNP$ (Valiant's $NP$)}{Polynomial family $\{f_n\}_n\in VNP$ of $$f_n(\overline{x})=\sum_{\underset{\substack{\downarrow\\ \text{witness}}}{\overline{w}\in \{0,1\}^{t(n)}}} \underset{\substack{\downarrow \\ \text{verifier}}}{g(\overline{x},\overline{w})}$$where $$t(n)=poly(n),\qquad \{g_n\}_n\in VP$$}
So a polynomial family $\{f_n\}\in VNP$ if $f_n$ can be written as a sum over witnesses with verifier evaluated. Replace $\sum$ with $\vee$ (in the boolean world) the you can recover definition of $NP$ right in the boolean case because $g=$ verifier algorithm, poly-time algorithm and it is just going over all possible certificates.

A standard problem in $VNP$ is \textbf{Permanent}$$\per_n(X_{n\times n})=\sum_{\pi\in Sym(n)} \prod_{i=1}^nx_{i,\pi(i)}$$
\qs{}{Why Gaussian Elimination would fail on this?}

\solve{Adding 2 rows or columns that does not change $\det$ but you don't know for $\per$. In general it change.}
\nt{So $\per$ is the hardest problem, even harder than $SAT$ in a way}

\thm{}{$\per\in VNP$}

	$$\per(X_{n\times n})=\sum_{\pi\in Sym(n)}\ \prod_{i=1}^nx_{i,\pi(i)}$$ $ \prod\limits_{i=1}^nx_{i,\pi(i)}$ is computable in $VP$ as this is a simple multiplication gate.
	
	So we can use this as a verifier. But problem is as you look at different summands for different permutations, from the permutation your verifier has to compute this which is not clear.

	
	\begin{center}
		\begin{tikzcd}[column sep={7.5em,between origins}]
			\per(X_{n\times n})=  \sum\limits_{\pi\in Sym(n)} &  \boxed{\prod\limits_{i=1}^nx_{i,\pi(i)} } \arrow[rrr, "\substack{\text{Think of }g\\ \text{that can compute this,}\\ \text{connect these two}}"', bend right=30] & 	&	f_n = \sum\limits_{\overline{w}\in \{0,1\}^{t(n)}} &\boxed{g_{n+t}(\overline{x},\overline{w})}
		\end{tikzcd}
	\end{center}

$\overline{w}$ is a just a string. So you have to make your permutation as a string. From that just using polynomial arithmetic it is not clear how to get to this $x_{i,\pi(i)}$
\parinf

\textbf{Observation: }\begin{enumerate}[label=(\roman*)]
	\item It is not direct. Does not follow from the definition
	\item Look for a more complicated $g$ instead of this monomial.
\end{enumerate}

\begin{proof}\parinn
	Let $g$ be the polynomial that takes $X_{n\times n}$matrix and $\overline{v}\in \{0,1\}^n$ and compute $$ g_{n^2+n} (X,\overline{v}) \dnt \underset{\substack{ \downarrow \\ \text{Produces}\\ \text{monomials} }}{\boxed{\prod_{i=1}^n\lt( \sum_{j=1}^nv_jX_{i,i} \rt) }  } \ \ \underset{\substack{ \downarrow \\ \text{Sign }=\\ \text{depending on}\\ \text{how many 1's in} \\ \overline{v},\text{ the weight of}  \\ \overline{v}\text{ will be sign}}}{  \boxed{\prod_{i=1}^n (2v_i-1)}  } $$
	
	\begin{claim}{Ryser's Formula \cite{ryser1963combinatorial}}{}
		$$\sum\limits_{\overline{v}\in \{0,1\}^n} g(X,\overline{v})=\per_n(X)$$
	\end{claim}
\begin{proof}
	Rewrite $LHS$ as $$\sum_{T\subseteq [n]}\ \  \prod_{i=1}^n\lt(  \sum_{j\in T }x_{ij}(-1)^{n-|T|} \rt)$$
	You are selecting some elements of the row and adding them, that is the $\sum x_{ij}$ for $j\in T$. And then you are going over all the rows $i=1$ to $n$ with a sign and then you are taking the big sum over all subsets. Since this is straddling over all the rows, it is basically multiplying the variables that appear in distinct rows.
	
	So it is supported on monomials $x_{1,i_1}\cdots x_{n,i_n}=m$, $r\dnt $ \# distinct $\{i_1,i_2,\dots, i_n\}$. We want to analyze the situation when this monomial does not correspond to a permutation which means $i_1,\dots,i_n$ are not distinct. We want to show this particular monomial will get ultimately canceled in the big sum. In how many $T$'s will this monomial  be produced ? $2^{n-r}$ many subsets of $T$. The monomial $m$ can be associated to $2^{n-r}$ many subsets $T$ with sign $=\sum\limits_{S\subseteq [n-r]} (-1)^{|S|}=0$ as $r<n$. For $\pi\in sym(n)$, $\prod\limits_{i=1}^n x_{i,\pi(i)}$ survives in $LHS$ with sign 1.
\end{proof}

Now $g\in VP$ because it is just a simple product. You compute these inner products by addition gates then you multiply by a single multiplication gate. So it is clearly depth 2 arithmetic circuit.

So $g$ is verifier and $\overline{v}$ is witness. So $\per_n\in VNP$
\end{proof}

\begin{conjecture}{Valiant's Conjecture}{}
	$VP\neq VNP$
\end{conjecture}
Then in that case $PER$ is $VNP-complete.$ $PER\notin VP$
\parinn

$PER$ of a boolean $(0/1)$ matrix, that represents a graph, is simply the number of perfect matching. To check if perfect matching exists has an algorithm. But to count them is harder than $NP-hard$ problems. This is equivalent to functional problem of $\#SAT$. (Valiant's $\#P-completeness$ of $PER$)

\dfn{$\#SAT$}{The problem of counting version of $SAT$. Formula satisfiability, boolean formula satisfiability. Given a boolean function how many satisfying assignments are true. For $n$ variables it can be 0 to $2^n$. Testing whether it is positive $NP-complete$ problem.}
 
This is called the Valiantâ€™s $\# P$ completeness of permanent which is Boolean permanent. So Valiant showed that permanent, the Boolean permanent or computing the permanent of a Boolean matrix which corresponds to a graph. This is equivalent to a $\# SAT$. And $\# SAT$ defines as a class which is called $\# P$.
\begin{Theorem}{[B\"{u}rgisser, 2000]}{}
	$VP=VNP\implies P/poly=NP/poly$. [This is much stronger than saying $P=NP$]
\end{Theorem}
From this you can not really deduce whether $P=NP$ or $P$ is different from $NP$. Because when you talk about $P$, $NP$ classes you talk about turing machines. You are not talking about Boolean Circuits. $P/poly$ is actually the problems that solve using Boolean Circuits and $NP/poly$ is also defined in the similar way using Boolean Circuits. SO the meaning of efficiency in Boolean Circuits and meaning of non-determinism in Boolean Circuits --- these two things are same ---  this is what the equality is saying.
\dfn{$NC^3$}{These are Boolean Circuits where depth is only $\log^3$}
\nt{B\"{u}rgisser also shows that $P/poly=NC^3/Poly$. So this exactly models very fast parallel algorithm. So on an input size of $n$ the parallel time complexity is only $\log^3$}
So if you show $VP=VNP$ then B\"{u}rgisser's proof actually tells you that $NP/poly=P/poly=NC^3$. So non-determinism is the same as efficient parallel algorithms. SO its is saying you can solve $SAT$ in fast parallel time.

When you are working over characteristic zero then B\"{u}rgisser's proof requires the assumption of \textit{GRH = Generalized Reimann Hypothesis}.